{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dc82b7a-781e-4d0d-b84f-e799f953b532",
   "metadata": {},
   "source": [
    "# Basic Face Detection and Recognition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3ea822-c557-41ea-b510-d34b941a3237",
   "metadata": {},
   "source": [
    "### Installing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bc3cef-9bed-4668-9a23-9f02ae56661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python\n",
    "pip install face_recognition\n",
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162e9bb7-8064-4128-a746-da80b0087ec6",
   "metadata": {},
   "source": [
    "### Detecting faces using Haar Cascades and Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e1c248-8d87-4327-8a08-597ad365ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "\n",
    "# Load the pre-trained HOG + SVM based face detector from dlib\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('me.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces\n",
    "faces = detector(gray)\n",
    "\n",
    "# Draw rectangles around detected faces\n",
    "for face in faces:\n",
    "    x, y, w, h = (face.left(), face.top(), face.width(), face.height())\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "# Show the output\n",
    "cv2.imshow('Face Detection', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f651209-5fb1-45bc-b88a-af976e8b8604",
   "metadata": {},
   "source": [
    "### Implementing comparsion between 2 faces and check if they match or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaca542-2f78-4e5e-a9a7-7a47d0d755da",
   "metadata": {},
   "source": [
    "#### Test Case - 1 : FACES MATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444da787-1d72-4b53-8d45-23bce73c2aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load known images and learn how to recognize them\n",
    "known_image = face_recognition.load_image_file('me.jpg')\n",
    "known_face_encoding = face_recognition.face_encodings(known_image)[0]\n",
    "\n",
    "# Load an image with an unknown face\n",
    "unknown_image = face_recognition.load_image_file('p1.jpg')\n",
    "unknown_face_encodings = face_recognition.face_encodings(unknown_image)\n",
    "\n",
    "# Flag to check if a match is found\n",
    "match_found = False\n",
    "\n",
    "# Compare faces\n",
    "for face_encoding in unknown_face_encodings:\n",
    "    results = face_recognition.compare_faces([known_face_encoding], face_encoding)\n",
    "\n",
    "    if results[0]:\n",
    "        match_message = \"It's a match!\"\n",
    "        match_found = True\n",
    "        break\n",
    "\n",
    "if not match_found:\n",
    "    match_message = \"No match found.\"\n",
    "\n",
    "# Function to display images side by side with a message\n",
    "def show_images_with_message(img1, img2, message, title1='Known Image', title2='Unknown Image'):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axes[0].imshow(img1)\n",
    "    axes[0].set_title(title1)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(img2)\n",
    "    axes[1].set_title(title2)\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    fig.suptitle(message, fontsize=16)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Display the known and unknown images with the match message\n",
    "show_images_with_message(known_image, unknown_image, match_message, title1='Known Image', title2='Unknown Image')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd4f8ba-ead6-4fcc-a47c-75ec1dfb8cc8",
   "metadata": {},
   "source": [
    "#### Test Case - 2 : FACES DO NOT MATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2850b82-95ec-4a5e-aaff-4cca3bb1f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load known images and learn how to recognize them\n",
    "known_image = face_recognition.load_image_file('me.jpg')\n",
    "known_face_encoding = face_recognition.face_encodings(known_image)[0]\n",
    "\n",
    "# Load an image with an unknown face\n",
    "unknown_image = face_recognition.load_image_file('p4.jpg')\n",
    "unknown_face_encodings = face_recognition.face_encodings(unknown_image)\n",
    "\n",
    "# Flag to check if a match is found\n",
    "match_found = False\n",
    "\n",
    "# Compare faces\n",
    "for face_encoding in unknown_face_encodings:\n",
    "    results = face_recognition.compare_faces([known_face_encoding], face_encoding)\n",
    "\n",
    "    if results[0]:\n",
    "        match_message = \"It's a match!\"\n",
    "        match_found = True\n",
    "        break\n",
    "\n",
    "if not match_found:\n",
    "    match_message = \"No match found.\"\n",
    "\n",
    "# Function to display images side by side with a message\n",
    "def show_images_with_message(img1, img2, message, title1='Known Image', title2='Unknown Image'):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axes[0].imshow(img1)\n",
    "    axes[0].set_title(title1)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(img2)\n",
    "    axes[1].set_title(title2)\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    fig.suptitle(message, fontsize=16)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Display the known and unknown images with the match message\n",
    "show_images_with_message(known_image, unknown_image, match_message, title1='Known Image', title2='Unknown Image')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e46fab-a3ec-4c4e-82af-6eadc2dbffa7",
   "metadata": {},
   "source": [
    "## GUI Model Using Tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef54163-abb8-4469-8b88-c758c32e448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import face_recognition\n",
    "from PIL import Image, ImageTk, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd7bb84-9ed5-4197-9033-289f527cf1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceRecognitionApp:\n",
    "    \"\"\"\n",
    "    FaceRecognitionApp class implements a GUI application for face detection and recognition using tkinter and face_recognition library.\n",
    "\n",
    "    Attributes:\n",
    "        root (tk.Tk): The main tkinter root window.\n",
    "        heading (tk.Label): Label for the main heading of the application.\n",
    "        subheading (tk.Label): Label for the subheading/welcome message.\n",
    "        upload_known_button (tk.Button): Button to upload the original face image.\n",
    "        upload_recognition_button (tk.Button): Button to upload an image for recognition.\n",
    "        result_label (tk.Label): Label to display the recognition result.\n",
    "        known_image (numpy.ndarray): Variable to store the loaded original face image.\n",
    "        known_face_encoding (numpy.ndarray): Variable to store the face encoding of the known image.\n",
    "        result_frame (tk.Frame): Frame to contain the result display elements.\n",
    "        original_image_panel (tk.Label): Label to display the original face image.\n",
    "        recognized_image_panel (tk.Label): Label to display the recognized face image.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root):\n",
    "        \"\"\"\n",
    "        Initializes the FaceRecognitionApp with the main tkinter root window.\n",
    "\n",
    "        Args:\n",
    "            root (tk.Tk): The main tkinter root window.\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.root.title(\"Face Recognition App\")\n",
    "        self.root.configure(bg='lightblue')\n",
    "\n",
    "        # Adding Heading\n",
    "        self.heading = tk.Label(root, text=\"Face Detection and Recognition System\", bg='blue', fg='white', font=('Arial', 20, 'bold'))\n",
    "        self.heading.pack(pady=10)\n",
    "\n",
    "        # Adding Subheading\n",
    "        self.subheading = tk.Label(root, text=\"Welcome to the Face Recognition App!\", bg='lightblue', fg='black', font=('Arial', 14))\n",
    "        self.subheading.pack(pady=5)\n",
    "\n",
    "        self.known_image = None\n",
    "        self.known_face_encoding = None\n",
    "\n",
    "        # Frame to hold images and result\n",
    "        self.result_frame = tk.Frame(root, bg='lightblue')\n",
    "        self.result_frame.pack(pady=20)\n",
    "\n",
    "        # Original face image panel\n",
    "        self.original_image_panel = tk.Label(self.result_frame, bg='lightblue')\n",
    "        self.original_image_panel.pack(side=\"left\", padx=10)\n",
    "\n",
    "        # Recognized face image panel\n",
    "        self.recognized_image_panel = tk.Label(self.result_frame, bg='lightblue')\n",
    "        self.recognized_image_panel.pack(side=\"left\", padx=10)\n",
    "\n",
    "        # Result label\n",
    "        self.result_label = tk.Label(root, text=\"\", bg='lightblue', fg='black', font=('Arial', 16))\n",
    "        self.result_label.pack(pady=10)\n",
    "\n",
    "        # Adding buttons\n",
    "        self.upload_known_button = tk.Button(root, text=\"Upload Original Face\", bg='green', fg='white', font=('Arial', 12, 'bold'), command=self.upload_known_image)\n",
    "        self.upload_known_button.pack(pady=10)\n",
    "\n",
    "        self.upload_recognition_button = tk.Button(root, text=\"Upload for Recognition\", bg='orange', fg='white', font=('Arial', 12, 'bold'), command=self.upload_for_recognition)\n",
    "        self.upload_recognition_button.pack(pady=10)\n",
    "\n",
    "    def upload_known_image(self):\n",
    "        \"\"\"\n",
    "        Allows user to upload the original face image and display it on the UI.\n",
    "        \"\"\"\n",
    "        file_path = filedialog.askopenfilename()\n",
    "        if file_path:\n",
    "            self.known_image = face_recognition.load_image_file(file_path)\n",
    "            self.known_face_encoding = face_recognition.face_encodings(self.known_image)[0]\n",
    "            self.display_original_image(self.known_image)\n",
    "\n",
    "    def upload_for_recognition(self):\n",
    "        \"\"\"\n",
    "        Allows user to upload an image for recognition, compares it with the original face image,\n",
    "        and displays the recognized face image with result on the UI.\n",
    "        \"\"\"\n",
    "        if self.known_face_encoding is None:\n",
    "            messagebox.showerror(\"Error\", \"Please upload a known image first.\")\n",
    "            return\n",
    "\n",
    "        file_path = filedialog.askopenfilename()\n",
    "        if file_path:\n",
    "            unknown_image = face_recognition.load_image_file(file_path)\n",
    "            face_locations = face_recognition.face_locations(unknown_image)\n",
    "            unknown_face_encodings = face_recognition.face_encodings(unknown_image, face_locations)\n",
    "\n",
    "            match_found = False\n",
    "            pil_unknown_image = Image.fromarray(unknown_image)\n",
    "            for face_encoding, face_location in zip(unknown_face_encodings, face_locations):\n",
    "                results = face_recognition.compare_faces([self.known_face_encoding], face_encoding)\n",
    "                status = \"match\" if results[0] else \"no_match\"\n",
    "                self.mark_face(pil_unknown_image, face_location, status)\n",
    "                if results[0]:\n",
    "                    match_found = True\n",
    "\n",
    "            if match_found:\n",
    "                result_text = \"It's a match!\"\n",
    "                result_bg = 'green'\n",
    "            else:\n",
    "                result_text = \"No match found.\"\n",
    "                result_bg = 'red'\n",
    "\n",
    "            self.display_recognized_image(pil_unknown_image, result_text, result_bg)\n",
    "\n",
    "    def mark_face(self, image, face_location, status):\n",
    "        \"\"\"\n",
    "        Marks the face on the given image with a colored rectangle based on the recognition status.\n",
    "\n",
    "        Args:\n",
    "            image (PIL.Image.Image): The image to mark.\n",
    "            face_location (tuple): Tuple containing coordinates (top, right, bottom, left) of the face.\n",
    "            status (str): Recognition status (\"match\" or \"no_match\").\n",
    "        \"\"\"\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        top, right, bottom, left = face_location\n",
    "        color = \"red\" if status == \"no_match\" else \"green\"\n",
    "        draw.rectangle(((left, top), (right, bottom)), outline=color, width=2)\n",
    "\n",
    "    def display_original_image(self, image):\n",
    "        \"\"\"\n",
    "        Displays the original face image on the UI.\n",
    "\n",
    "        Args:\n",
    "            image (numpy.ndarray): The original face image.\n",
    "        \"\"\"\n",
    "        img = Image.fromarray(image).resize((200, 200), Image.LANCZOS)\n",
    "        img_tk = ImageTk.PhotoImage(img)\n",
    "        self.original_image_panel.config(image=img_tk)\n",
    "        self.original_image_panel.image = img_tk\n",
    "\n",
    "    def display_recognized_image(self, image, result_text, result_bg):\n",
    "        \"\"\"\n",
    "        Displays the recognized face image and result on the UI.\n",
    "\n",
    "        Args:\n",
    "            image (PIL.Image.Image): The recognized face image.\n",
    "            result_text (str): Text describing the recognition result.\n",
    "            result_bg (str): Background color for the result display (\"green\" for match, \"red\" for no match).\n",
    "        \"\"\"\n",
    "        img = ImageTk.PhotoImage(image.resize((200, 200), Image.LANCZOS))\n",
    "        self.recognized_image_panel.config(image=img)\n",
    "        self.recognized_image_panel.image = img\n",
    "        self.result_label.config(text=result_text, bg=result_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835acb83-c519-4f93-84ff-8c17a9dc025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = FaceRecognitionApp(root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225264e-685a-4228-93ba-86fd8f0cca13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
